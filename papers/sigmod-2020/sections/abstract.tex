\begin{abstract}
Effective collaboration between data scientists results in high-quality and efficient machine learning (ML) workloads.
In a collaborative environment, such as Kaggle or Google Colabratory, users typically re-execute or modify published scripts to recreate or improve the result.
This introduces many redundant data processing and model training operations.
Reusing the data generated by the redundant operations can lead to the more efficient execution of future workloads.
However, existing collaborative environments lack a data management component for storing and reusing the result of previously applied operations.

In this paper, we present a system to optimize the execution of ML workloads in collaborative environments by reusing previously performed operations and their intermediate results.
We utilize a so-called Experiment Graph (EG) to store the artifacts, i.e., raw and intermediate data or ML models, as vertices and operations of ML workloads as edges.
In theory, the size of the EG can become unnecessarily large while the storage budget might be limited. 
At the same time, for some artifacts, the overall storage and retrieval cost might outweigh the recomputation cost.
To address this issue, we propose two algorithms for materializing artifacts based on their likelihood of future reuse.
Given the materialized artifacts inside the EG, we devise a linear time reuse algorithm to find the optimal execution plan for incoming ML workloads.
Our reuse algorithm only incurs a negligible overhead and scales for the high number of incoming ML workloads.
\hl{One sentence about the experiment results.}
\end{abstract}